{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza i projektiranje računalom - 3. domaća zadaća"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U okviru ove domaće zadaće potrebno je implementirati sljedeće metode optimiranja:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcije cilja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija 1 - Rosenbrockova \"banana\" funkcija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_1 \\left( \\vec{x} \\right) = 100 \\left( x_1 - {x_0}^2 \\right)^2 + \\left( 1 - x_0 \\right)^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_0} = \n",
    "    \\begin{bmatrix}\n",
    "        -1.9 & 2\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_{min}} =\n",
    "    \\begin{bmatrix}\n",
    "        1 & 1\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_1 \\left( \\vec{x_{min}} \\right) = 0\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_2 \\left( \\vec{x} \\right) = \\left( x_0 - 4 \\right)^2 + 4 \\left( x_1 - 2 \\right)^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_0} = \n",
    "    \\begin{bmatrix}\n",
    "        0.1 & 0.3\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_{min}} =\n",
    "    \\begin{bmatrix}\n",
    "        4 & 2\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_2 \\left( \\vec{x_{min}} \\right) = 0\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_3 \\left( \\vec{x} \\right) = \\left( x_0 - 2 \\right)^2 + \\left( x_1 + 3 \\right)^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_0} = \n",
    "    \\begin{bmatrix}\n",
    "        0 & 0\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_{min}} =\n",
    "    \\begin{bmatrix}\n",
    "        2 & -3\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_3 \\left( \\vec{x_{min}} \\right) = 0\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcija 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_4 \\left( \\vec{x} \\right) = \\left( x_0 - 3 \\right)^2 + {x_1}^2\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_0} = \n",
    "    \\begin{bmatrix}\n",
    "        0 & 0\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    \\vec{x_{min}} =\n",
    "    \\begin{bmatrix}\n",
    "        3 & 0\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "    f_4 \\left( \\vec{x_{min}} \\right) = 0\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priprema za izvođenje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CD_KEY = \"--HW03_IN_ROOT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/projekti/faks/AIPR/dz/dz-03\n"
     ]
    }
   ],
   "source": [
    "if (\n",
    "    CD_KEY not in os.environ\n",
    "    or os.environ[CD_KEY] is None\n",
    "    or len(os.environ[CD_KEY]) == 0\n",
    "    or os.environ[CD_KEY] == \"false\"\n",
    "):\n",
    "    %cd ..\n",
    "else:\n",
    "    print(os.getcwd())\n",
    "    \n",
    "os.environ[CD_KEY] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Učitavanje paketa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import array_to_latex as a2l\n",
    "from IPython.display import display, Markdown\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.searches.function import Function\n",
    "from src.searches.gradient_descent import gradient_descent_search\n",
    "from src.searches.newton_raphson import newton_raphson_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicija pomoćnih funkcija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_latex(array):\n",
    "    return a2l.to_ltx(\n",
    "        array,\n",
    "        frmt=\"{:g}\",\n",
    "        arraytype=\"bmatrix\",\n",
    "        print_out=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicija funkcija i početnih točaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Function(lambda x: 100 * (x[1] - x[0] ** 2) ** 2 + (1 - x[0]) ** 2)\n",
    "f1_derivative = Function(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            2 * (200 * x[0] ** 3 - 200 * x[0] * x[1] + x[0] - 1),\n",
    "            200 * (x[1] - x[0] ** 2)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "f1_hesse = Function(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            [2 * (600 * x[0] ** 2 - 200 * x[1] + 1), -400 * x[0]],\n",
    "            [-400 * x[0], 200]\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "f1_derivative.derivative = f1_hesse\n",
    "f1.derivative = f1_derivative\n",
    "\n",
    "f1_start = np.array([-1.9, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = Function(lambda x: (x[0] - 4) ** 2 + 4 * (x[1] - 2) ** 2)\n",
    "f2_derivative = Function(\n",
    "    lambda x: np.array([2 * x[0] - 8, 8 * x[1] - 16])\n",
    ")\n",
    "f2_hesse = Function(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            [2, 0],\n",
    "            [0, 8]\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "f2_derivative.derivative = f2_hesse\n",
    "f2.derivative = f2_derivative\n",
    "\n",
    "f2_start = np.array([0.1, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = Function(lambda x: (x[0] - 2) ** 2 + (x[1] + 3) ** 2)\n",
    "f3_derivative = Function(\n",
    "    lambda x: np.array([2 * x[0] - 4, 2 * x[1] + 6])\n",
    ")\n",
    "f3_hesse = Function(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            [2, 0],\n",
    "            [0, 2]\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "f3_derivative.derivative = f3_hesse\n",
    "f3.derivative = f3_derivative\n",
    "\n",
    "f3_start = np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = Function(lambda x: (x[0] - 3) ** 2 + x[1] ** 2)\n",
    "f4_derivative = Function(\n",
    "    lambda x: np.array([2 * x[0] - 6, 2 * x[1]])\n",
    ")\n",
    "f4_hesse = Function(\n",
    "    lambda x: np.array(\n",
    "        [\n",
    "            [2, 0],\n",
    "            [0, 2]\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "f4.derivative = f4_derivative\n",
    "\n",
    "f4_start = np.array([0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadatci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primijenite postupak gradijentnog spusta na funkciju 3, uz i bez određivanje optimalnog iznosa koraka. Što možete zaključiti iz rezultata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_start = copy.deepcopy(f1_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uz određivanje optimalnog iznosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_function_with_optimal_step = f3.get_new()\n",
    "\n",
    "t1_result_with_optimal_step = gradient_descent_search(\n",
    "    function=t1_function_with_optimal_step,\n",
    "    start=t1_start,\n",
    "    gradient_scaling=\"find optimal\",\n",
    ")\n",
    "t1_value_with_optimal_step = t1_function_with_optimal_step(\n",
    "    t1_result_with_optimal_step, dont_count=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Postupak gradijentnog spusta** pronašao je minimumu točki $\\begin{bmatrix}\n",
       "  2  & -3 \n",
       "\\end{bmatrix}$ vrijednosti $1.04097e-26$ (uz $75$ poziva funkcije i $3$ poziva gradijenta)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Postupak gradijentnog spusta** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t1_result_with_optimal_step)}$ \"\n",
    "        f\"vrijednosti ${t1_value_with_optimal_step:g}$ \"\n",
    "        f\"(uz ${t1_function_with_optimal_step.call_count}$ poziva funkcije \"\n",
    "        f\"i ${t1_function_with_optimal_step.derivative.call_count}$ \"\n",
    "        \"poziva gradijenta).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uz normalizaciju gradijenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient descent timed out after 100 iterations passed with no improvement.\n"
     ]
    }
   ],
   "source": [
    "t1_function_with_normalize = f3.get_new()\n",
    "\n",
    "t1_result_with_normalize = gradient_descent_search(\n",
    "    function=t1_function_with_normalize,\n",
    "    start=t1_start,\n",
    "    gradient_scaling=\"normalize\",\n",
    ")\n",
    "t1_value_with_normalize = t1_function_with_normalize(\n",
    "    t1_result_with_normalize, dont_count=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Postupak gradijentnog spusta** pronašao je minimumu točki $\\begin{bmatrix}\n",
       "  1.79019 & -2.73101\n",
       "\\end{bmatrix}$ vrijednosti $0.116373$ (uz $107$ poziva funkcije i $106$ poziva gradijenta)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Postupak gradijentnog spusta** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t1_result_with_normalize)}$ \"\n",
    "        f\"vrijednosti ${t1_value_with_normalize:g}$ \"\n",
    "        f\"(uz ${t1_function_with_normalize.call_count}$ poziva funkcije \"\n",
    "        f\"i ${t1_function_with_normalize.derivative.call_count}$ \"\n",
    "        \"poziva gradijenta).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez modifikacija gradijenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient descent timed out after 100 iterations passed with no improvement.\n"
     ]
    }
   ],
   "source": [
    "t1_function_vanilla = f3.get_new()\n",
    "\n",
    "t1_result_vanilla = gradient_descent_search(\n",
    "    function=t1_function_vanilla,\n",
    "    start=t1_start,\n",
    "    gradient_scaling=\"none\",\n",
    ")\n",
    "t1_value_vanilla = t1_function_vanilla(\n",
    "    t1_result_vanilla, dont_count=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Postupak gradijentnog spusta** pronašao je minimumu točki $\\begin{bmatrix}\n",
       " -1.9 &  2 \n",
       "\\end{bmatrix}$ vrijednosti $40.21$ (uz $101$ poziva funkcije i $100$ poziva gradijenta)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Postupak gradijentnog spusta** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t1_result_vanilla)}$ \"\n",
    "        f\"vrijednosti ${t1_value_vanilla:g}$ \"\n",
    "        f\"(uz ${t1_function_vanilla.call_count}$ poziva funkcije \"\n",
    "        f\"i ${t1_function_vanilla.derivative.call_count}$ \"\n",
    "        \"poziva gradijenta).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**: Iz rezultata je jednostavno zaključiti da algoritam ne konvergira naivnim pristupom određivanja gradijenta. Konvergencija se događa samo kada odaberemo optimalan korak. U slučaju gdje ga normaliziramo, pretraga zapne. U slučaju kada ostavimo gradijent takav kakav je, zapnemo u nekoj drugoj točki dosta veće vrijednosti od slučaja kad ga normaliziramo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadatak 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primijenite postupak gradijentnog spusta i Newton-Raphsonov postupak na funkcije 1 i 2 s određivanjem optimalnog iznosa koraka. Ispišite broj izračuna funkcije, gradijenta i Hesseove matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f1_start = copy.deepcopy(f1_start)\n",
    "t2_f2_start = copy.deepcopy(f2_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcija 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f1_gd = f1.get_new()\n",
    "t2_f1_nr = f1.get_new()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradijentni spust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f1_gd_result = gradient_descent_search(\n",
    "    function=t2_f1_gd,\n",
    "    start=t2_f1_start,\n",
    "    gradient_scaling=\"find optimal\",\n",
    ")\n",
    "t2_f1_gd_value = t2_f1_gd(t2_f1_gd_result, dont_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Postupak gradijentnog spusta** pronašao je minimumu točki $\\begin{bmatrix}\n",
       "  1  &  1 \n",
       "\\end{bmatrix}$ vrijednosti $1.06955e-12$ (uz $150961$ poziva funkcije i $4081$ poziva gradijenta)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Postupak gradijentnog spusta** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t2_f1_gd_result)}$ \"\n",
    "        f\"vrijednosti ${t2_f1_gd_value:g}$ \"\n",
    "        f\"(uz ${t2_f1_gd.call_count}$ poziva funkcije \"\n",
    "        f\"i ${t2_f1_gd.derivative.call_count}$ \"\n",
    "        \"poziva gradijenta).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f1_nr_result = newton_raphson_search(\n",
    "    function=t2_f1_nr,\n",
    "    start=t2_f1_start,\n",
    "    stride_scaling=\"find optimal\",\n",
    ")\n",
    "t2_f1_nr_value = t2_f1_nr(t2_f1_nr_result, dont_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Newton-Raphsonov postupak** pronašao je minimumu točki $\\begin{bmatrix}\n",
       "  1  &  1 \n",
       "\\end{bmatrix}$ vrijednosti $3.62541e-13$ (uz $541$ poziva funkcije, $15$ poziva gradijenta i $15$ poziva Hesseove matrice)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Newton-Raphsonov postupak** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t2_f1_nr_result)}$ \"\n",
    "        f\"vrijednosti ${t2_f1_nr_value:g}$ \"\n",
    "        f\"(uz ${t2_f1_nr.call_count}$ poziva funkcije, \"\n",
    "        f\"${t2_f1_nr.derivative.call_count}$ poziva gradijenta \"\n",
    "        f\"i ${t2_f1_nr.derivative.derivative.call_count}$ \"\n",
    "        \"poziva Hesseove matrice).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcija 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f2_gd = f2.get_new()\n",
    "t2_f2_nr = f2.get_new()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradijentni spust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f2_gd_result = gradient_descent_search(\n",
    "    function=t2_f2_gd,\n",
    "    start=t2_f2_start,\n",
    "    gradient_scaling=\"find optimal\",\n",
    ")\n",
    "t2_f2_gd_value = t2_f2_gd(t2_f2_gd_result, dont_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Postupak gradijentnog spusta** pronašao je minimumu točki $\\begin{bmatrix}\n",
       "  4  &  2 \n",
       "\\end{bmatrix}$ vrijednosti $1.33413e-13$ (uz $1000$ poziva funkcije i $28$ poziva gradijenta)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Postupak gradijentnog spusta** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t2_f2_gd_result)}$ \"\n",
    "        f\"vrijednosti ${t2_f2_gd_value:g}$ \"\n",
    "        f\"(uz ${t2_f2_gd.call_count}$ poziva funkcije \"\n",
    "        f\"i ${t2_f2_gd.derivative.call_count}$ \"\n",
    "        \"poziva gradijenta).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_f2_nr_result = newton_raphson_search(\n",
    "    function=t2_f2_nr,\n",
    "    start=t2_f2_start,\n",
    "    stride_scaling=\"find optimal\",\n",
    ")\n",
    "t2_f2_nr_value = t2_f2_nr(t2_f2_nr_result, dont_count=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Newton-Raphsonov postupak** pronašao je minimumu točki $\\begin{bmatrix}\n",
       "  4  &  2 \n",
       "\\end{bmatrix}$ vrijednosti $1.12834e-12$ (uz $39$ poziva funkcije, $2$ poziva gradijenta i $2$ poziva Hesseove matrice)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Markdown(\n",
    "        \"**Newton-Raphsonov postupak** pronašao je minimum\"\n",
    "        f\"u točki ${array_to_latex(t2_f2_nr_result)}$ \"\n",
    "        f\"vrijednosti ${t2_f2_nr_value:g}$ \"\n",
    "        f\"(uz ${t2_f2_nr.call_count}$ poziva funkcije, \"\n",
    "        f\"${t2_f2_nr.derivative.call_count}$ poziva gradijenta \"\n",
    "        f\"i ${t2_f2_nr.derivative.derivative.call_count}$ \"\n",
    "        \"poziva Hesseove matrice).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako se Newton-Raphsonov postupak ponaša na ovim funkcijama?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Odgovor**: Vidimo da oba algoritma pronalaze minimume. U slučaju **Newton-Raphsonovog postupka** nalaze se nešto precizniji minimumi (vjerojatno radi malo drukčkije formulacije kriterija zaustavljanja), ali je veća razlika znatno manji broj poziva funkcija, gradijenata i Hesseove matrice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipr_dz03",
   "language": "python",
   "name": "aipr_dz03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
